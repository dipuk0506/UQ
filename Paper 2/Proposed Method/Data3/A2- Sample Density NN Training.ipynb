{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8e20b9c",
   "metadata": {
    "papermill": {
     "duration": 0.009018,
     "end_time": "2022-04-17T13:24:34.978927",
     "exception": false,
     "start_time": "2022-04-17T13:24:34.969909",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3291ce97",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-17T13:24:34.997715Z",
     "iopub.status.busy": "2022-04-17T13:24:34.996955Z",
     "iopub.status.idle": "2022-04-17T13:24:35.070458Z",
     "shell.execute_reply": "2022-04-17T13:24:35.069738Z"
    },
    "papermill": {
     "duration": 0.086564,
     "end_time": "2022-04-17T13:24:35.073216",
     "exception": false,
     "start_time": "2022-04-17T13:24:34.986652",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Similar Samples Considered 100\n",
      "Target Shape (5000,) Similar Samples Matrix Shape: (5000, 100)\n"
     ]
    }
   ],
   "source": [
    "import pickle as pkl\n",
    "\n",
    "fileName =  '../input/a1-data-to-similar-events/Similarity'\n",
    "fileObject2 = open(fileName, 'rb')\n",
    "Imported_data = pkl.load(fileObject2)\n",
    "fileObject2.close()\n",
    "\n",
    "#print('Similarity Thresholds:',Imported_data[:,0])\n",
    "\n",
    "#print('Most Similarity at:',Imported_data[:,1])\n",
    "\n",
    "Similar_event_count = len(Imported_data[0,:])-1\n",
    "print('Number of Similar Samples Considered', Similar_event_count)\n",
    "\n",
    "Similarity_thresholds = Imported_data[:,0]\n",
    "\n",
    "Sample_density = Similar_event_count/ Similarity_thresholds/100\n",
    "#Sample_density = number of samples with less than 1% (of range) deviation\n",
    "\n",
    "Similar_samples = Imported_data[:,1:Similar_event_count+1]\n",
    "\n",
    "print('Target Shape', Sample_density.shape, 'Similar Samples Matrix Shape:', Similar_samples.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e228cdf7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-17T13:24:35.093053Z",
     "iopub.status.busy": "2022-04-17T13:24:35.092337Z",
     "iopub.status.idle": "2022-04-17T13:24:35.146966Z",
     "shell.execute_reply": "2022-04-17T13:24:35.146091Z"
    },
    "papermill": {
     "duration": 0.067154,
     "end_time": "2022-04-17T13:24:35.149304",
     "exception": false,
     "start_time": "2022-04-17T13:24:35.082150",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input1</th>\n",
       "      <th>Input2</th>\n",
       "      <th>Input3</th>\n",
       "      <th>Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.659116</td>\n",
       "      <td>4.673695</td>\n",
       "      <td>1.231898</td>\n",
       "      <td>-1.010633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.172297</td>\n",
       "      <td>0.308095</td>\n",
       "      <td>6.197296</td>\n",
       "      <td>0.140169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.620350</td>\n",
       "      <td>3.752477</td>\n",
       "      <td>3.010036</td>\n",
       "      <td>0.014108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.269573</td>\n",
       "      <td>3.173038</td>\n",
       "      <td>6.019555</td>\n",
       "      <td>-0.016590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.946378</td>\n",
       "      <td>3.264015</td>\n",
       "      <td>2.245954</td>\n",
       "      <td>1.222183</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Input1    Input2    Input3    Output\n",
       "0  2.659116  4.673695  1.231898 -1.010633\n",
       "1  6.172297  0.308095  6.197296  0.140169\n",
       "2  1.620350  3.752477  3.010036  0.014108\n",
       "3  6.269573  3.173038  6.019555 -0.016590\n",
       "4  3.946378  3.264015  2.245954  1.222183"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_csv_path = '../input/toy-dataset-for-regression-and-uq/Data3_Train.csv'\n",
    "test_csv_path = '../input/toy-dataset-for-regression-and-uq/Data3_Test.csv'\n",
    "val_csv_path = '../input/toy-dataset-for-regression-and-uq/Data3_Val.csv'\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "train_df = pd.read_csv(train_csv_path)\n",
    "val_df = pd.read_csv(val_csv_path)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1fe952",
   "metadata": {
    "papermill": {
     "duration": 0.00819,
     "end_time": "2022-04-17T13:24:35.165945",
     "exception": false,
     "start_time": "2022-04-17T13:24:35.157755",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training-Validation Splitting\n",
    "The training Dataset is split, as top matches and sample densities are computed on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fe7eab2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-17T13:24:35.184990Z",
     "iopub.status.busy": "2022-04-17T13:24:35.184405Z",
     "iopub.status.idle": "2022-04-17T13:24:37.650167Z",
     "shell.execute_reply": "2022-04-17T13:24:37.648984Z"
    },
    "papermill": {
     "duration": 2.477722,
     "end_time": "2022-04-17T13:24:37.652310",
     "exception": false,
     "start_time": "2022-04-17T13:24:35.174588",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "Shape of training input: torch.Size([4000, 3])\n",
      "Shape of validation input: torch.Size([1000, 3])\n",
      "tensor(720.4310) tensor(33.3519) tensor([6.2822, 6.2817, 6.2823]) tensor([4.0563e-04, 6.2234e-05, 9.0123e-04])\n",
      "tensor([6.2818, 6.2816, 6.2814]) tensor(687.0790)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import imageio\n",
    "\n",
    "input_=[]\n",
    "output_=[]\n",
    "for row in train_df.iloc:\n",
    "    input_.append((row[0:len(row)-1]).astype(float))\n",
    "    output_.append(row[-1])\n",
    "    \n",
    "    \n",
    "num_input = len(row)-1;\n",
    "print(num_input)\n",
    "\n",
    "torch.manual_seed(1)    # reproducible\n",
    "\n",
    "x = torch.tensor(input_[0:4000]).float()  \n",
    "print('Shape of training input:',x.shape)\n",
    "y = torch.tensor(Sample_density[0:4000]).float()   \n",
    "new_shape = (len(y), 1)\n",
    "y = y.view(new_shape)\n",
    "\n",
    "\n",
    "i_val = torch.tensor(input_[4000:5000]).float()  \n",
    "print('Shape of validation input:',i_val.shape)\n",
    "o_val = torch.tensor(Sample_density[4000:5000]).float()   \n",
    "new_shape = (len(o_val), 1)\n",
    "o_val = o_val.view(new_shape)\n",
    "\n",
    "\n",
    "\n",
    "max_y = torch.max(y[:,0])\n",
    "min_y =torch.min(y[:,0])\n",
    "\n",
    "max_x = torch.max(x,dim=0)\n",
    "min_x = torch.min(x,dim=0)\n",
    "\n",
    "print(max_y, min_y, max_x.values, min_x.values)\n",
    "\n",
    "range_y = max_y - min_y\n",
    "range_x = max_x.values - min_x.values\n",
    "\n",
    "print(range_x, range_y)\n",
    "\n",
    "    #Normalizing\n",
    "x = (x - min_x.values)/range_x\n",
    "y = (y - min_y)/range_y\n",
    "\n",
    "i_val = (i_val - min_x.values)/range_x\n",
    "o_val = (o_val - min_y)/range_y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e2c8bc",
   "metadata": {
    "papermill": {
     "duration": 0.008601,
     "end_time": "2022-04-17T13:24:37.669766",
     "exception": false,
     "start_time": "2022-04-17T13:24:37.661165",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Sample Density NN Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "823a0366",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-17T13:24:37.689537Z",
     "iopub.status.busy": "2022-04-17T13:24:37.689120Z",
     "iopub.status.idle": "2022-04-17T13:25:16.555038Z",
     "shell.execute_reply": "2022-04-17T13:25:16.554117Z"
    },
    "papermill": {
     "duration": 38.891294,
     "end_time": "2022-04-17T13:25:16.570066",
     "exception": false,
     "start_time": "2022-04-17T13:24:37.678772",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (hidden): Linear(in_features=3, out_features=500, bias=True)\n",
      "  (hidden2): Linear(in_features=500, out_features=500, bias=True)\n",
      "  (predict): Linear(in_features=500, out_features=1, bias=True)\n",
      ")\n",
      "Epoch [200/600], Loss: 0.0119, Minimum Loss 0.011922, Val Loss 0.014002  \n",
      "Epoch [400/600], Loss: 0.0109, Minimum Loss 0.010913, Val Loss 0.013145  \n",
      "Epoch [600/600], Loss: 0.0103, Minimum Loss 0.010335, Val Loss 0.012707  \n"
     ]
    }
   ],
   "source": [
    "# torch can only train on Variable, so convert them to Variable\n",
    "x, y = Variable(x), Variable(y)\n",
    " \n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, n_feature, n_hidden, n_output):\n",
    "        super(Net, self).__init__()\n",
    "        self.hidden = torch.nn.Linear(n_feature, n_hidden)   # hidden layer\n",
    "        self.hidden2 = torch.nn.Linear(n_hidden, n_hidden)   # hidden layer\n",
    "        self.predict = torch.nn.Linear(n_hidden, n_output)   # output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.hidden(x))      # activation function for hidden layer\n",
    "        x = F.relu(self.hidden2(x))\n",
    "        x = self.predict(x)             # linear output\n",
    "        return x\n",
    "\n",
    "# use the same net as before      \n",
    "net = Net(n_feature=num_input, n_hidden=500, n_output=1)     # define the network\n",
    "print(net)  # net architecture\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.05)\n",
    "loss_func = torch.nn.MSELoss()  # this is for regression mean squared loss\n",
    "\n",
    "\n",
    "minimum_train_loss = 1e5\n",
    "minimum_val_loss = 1e5\n",
    "EPOCH = 600\n",
    "\n",
    "# start training\n",
    "for epoch in range(EPOCH):\n",
    "  \n",
    "    prediction = net(x)     # input x and predict based on x\n",
    "\n",
    "    loss = loss_func(prediction, y)     # must be (1. nn output, 2. target)\n",
    "\n",
    "    optimizer.zero_grad()   # clear gradients for next train\n",
    "    loss.backward()         # backpropagation, compute gradients\n",
    "    optimizer.step()        # apply gradients\n",
    "    \n",
    "    if loss<minimum_train_loss:\n",
    "        minimum_train_loss =loss\n",
    "        net_opt = net\n",
    "    \n",
    "    if epoch%200 == 199:\n",
    "      prediction = net_opt(i_val)\n",
    "      loss_val = loss_func(prediction, o_val)\n",
    "      if loss_val<minimum_val_loss:\n",
    "        minimum_val_loss = loss_val\n",
    "        net_opt_val = net_opt\n",
    "      print (\"Epoch [{}/{}], Loss: {:.4f}, Minimum Loss {:.6f}, Val Loss {:.6f}  \"  .format(epoch+1, EPOCH, loss, minimum_train_loss, minimum_val_loss))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 52.042707,
   "end_time": "2022-04-17T13:25:17.403434",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-04-17T13:24:25.360727",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
