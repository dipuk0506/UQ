{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "armed-intent",
   "metadata": {
    "papermill": {
     "duration": 0.014523,
     "end_time": "2022-08-03T01:02:22.140955",
     "exception": false,
     "start_time": "2022-08-03T01:02:22.126432",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "published-glucose",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-03T01:02:22.171172Z",
     "iopub.status.busy": "2022-08-03T01:02:22.170553Z",
     "iopub.status.idle": "2022-08-03T01:02:22.255850Z",
     "shell.execute_reply": "2022-08-03T01:02:22.256421Z",
     "shell.execute_reply.started": "2022-08-03T00:54:46.824500Z"
    },
    "papermill": {
     "duration": 0.103548,
     "end_time": "2022-08-03T01:02:22.256743",
     "exception": false,
     "start_time": "2022-08-03T01:02:22.153195",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Adult Mortality</th>\n",
       "      <th>Infant Deaths</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Expenditure(%)</th>\n",
       "      <th>Hepatitis B</th>\n",
       "      <th>Measles</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Under-five Deaths</th>\n",
       "      <th>Polio</th>\n",
       "      <th>Total expenditure</th>\n",
       "      <th>Diphtheria</th>\n",
       "      <th>HIV/AIDS</th>\n",
       "      <th>GDP</th>\n",
       "      <th>Population</th>\n",
       "      <th>Thinness  1-19 Years</th>\n",
       "      <th>Thinness 5-9 Years</th>\n",
       "      <th>ICOR</th>\n",
       "      <th>Schooling</th>\n",
       "      <th>Life Expectancy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015</td>\n",
       "      <td>263.0</td>\n",
       "      <td>62</td>\n",
       "      <td>0.01</td>\n",
       "      <td>71.279624</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1154</td>\n",
       "      <td>19.1</td>\n",
       "      <td>83</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.16</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>584.259210</td>\n",
       "      <td>33736494.0</td>\n",
       "      <td>17.2</td>\n",
       "      <td>17.3</td>\n",
       "      <td>0.479</td>\n",
       "      <td>10.1</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014</td>\n",
       "      <td>271.0</td>\n",
       "      <td>64</td>\n",
       "      <td>0.01</td>\n",
       "      <td>73.523582</td>\n",
       "      <td>62.0</td>\n",
       "      <td>492</td>\n",
       "      <td>18.6</td>\n",
       "      <td>86</td>\n",
       "      <td>58.0</td>\n",
       "      <td>8.18</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>612.696514</td>\n",
       "      <td>327582.0</td>\n",
       "      <td>17.5</td>\n",
       "      <td>17.5</td>\n",
       "      <td>0.476</td>\n",
       "      <td>10.0</td>\n",
       "      <td>59.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013</td>\n",
       "      <td>268.0</td>\n",
       "      <td>66</td>\n",
       "      <td>0.01</td>\n",
       "      <td>73.219243</td>\n",
       "      <td>64.0</td>\n",
       "      <td>430</td>\n",
       "      <td>18.1</td>\n",
       "      <td>89</td>\n",
       "      <td>62.0</td>\n",
       "      <td>8.13</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>631.744976</td>\n",
       "      <td>31731688.0</td>\n",
       "      <td>17.7</td>\n",
       "      <td>17.7</td>\n",
       "      <td>0.470</td>\n",
       "      <td>9.9</td>\n",
       "      <td>59.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012</td>\n",
       "      <td>272.0</td>\n",
       "      <td>69</td>\n",
       "      <td>0.01</td>\n",
       "      <td>78.184215</td>\n",
       "      <td>67.0</td>\n",
       "      <td>2787</td>\n",
       "      <td>17.6</td>\n",
       "      <td>93</td>\n",
       "      <td>67.0</td>\n",
       "      <td>8.52</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>669.959000</td>\n",
       "      <td>3696958.0</td>\n",
       "      <td>17.9</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.463</td>\n",
       "      <td>9.8</td>\n",
       "      <td>59.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011</td>\n",
       "      <td>275.0</td>\n",
       "      <td>71</td>\n",
       "      <td>0.01</td>\n",
       "      <td>7.097109</td>\n",
       "      <td>68.0</td>\n",
       "      <td>3013</td>\n",
       "      <td>17.2</td>\n",
       "      <td>97</td>\n",
       "      <td>68.0</td>\n",
       "      <td>7.87</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>63.537231</td>\n",
       "      <td>2978599.0</td>\n",
       "      <td>18.2</td>\n",
       "      <td>18.2</td>\n",
       "      <td>0.454</td>\n",
       "      <td>9.5</td>\n",
       "      <td>59.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Adult Mortality  Infant Deaths  Alcohol  Expenditure(%)  Hepatitis B  \\\n",
       "0  2015            263.0             62     0.01       71.279624         65.0   \n",
       "1  2014            271.0             64     0.01       73.523582         62.0   \n",
       "2  2013            268.0             66     0.01       73.219243         64.0   \n",
       "3  2012            272.0             69     0.01       78.184215         67.0   \n",
       "4  2011            275.0             71     0.01        7.097109         68.0   \n",
       "\n",
       "   Measles    BMI   Under-five Deaths  Polio  Total expenditure  Diphtheria   \\\n",
       "0      1154   19.1                 83    6.0               8.16         65.0   \n",
       "1       492   18.6                 86   58.0               8.18         62.0   \n",
       "2       430   18.1                 89   62.0               8.13         64.0   \n",
       "3      2787   17.6                 93   67.0               8.52         67.0   \n",
       "4      3013   17.2                 97   68.0               7.87         68.0   \n",
       "\n",
       "    HIV/AIDS         GDP  Population   Thinness  1-19 Years  \\\n",
       "0        0.1  584.259210  33736494.0                   17.2   \n",
       "1        0.1  612.696514    327582.0                   17.5   \n",
       "2        0.1  631.744976  31731688.0                   17.7   \n",
       "3        0.1  669.959000   3696958.0                   17.9   \n",
       "4        0.1   63.537231   2978599.0                   18.2   \n",
       "\n",
       "    Thinness 5-9 Years   ICOR  Schooling  Life Expectancy  \n",
       "0                 17.3  0.479       10.1             65.0  \n",
       "1                 17.5  0.476       10.0             59.9  \n",
       "2                 17.7  0.470        9.9             59.9  \n",
       "3                 18.0  0.463        9.8             59.5  \n",
       "4                 18.2  0.454        9.5             59.2  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_path = '../input/life-expectancy-who-pre-process/Life_expectancy_last_column.csv'\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv(csv_path, index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "narrow-stanley",
   "metadata": {
    "papermill": {
     "duration": 0.010282,
     "end_time": "2022-08-03T01:02:22.277967",
     "exception": false,
     "start_time": "2022-08-03T01:02:22.267685",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Considerations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "indirect-resistance",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-03T01:02:22.302728Z",
     "iopub.status.busy": "2022-08-03T01:02:22.301732Z",
     "iopub.status.idle": "2022-08-03T01:02:22.306144Z",
     "shell.execute_reply": "2022-08-03T01:02:22.306712Z",
     "shell.execute_reply.started": "2022-08-03T00:54:46.874494Z"
    },
    "papermill": {
     "duration": 0.018431,
     "end_time": "2022-08-03T01:02:22.306885",
     "exception": false,
     "start_time": "2022-08-03T01:02:22.288454",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Similar_event_count = 100\n",
    "sensitivity_consideration = 1\n",
    "error_sensitivity_consideration = 1\n",
    "\n",
    "# Error-Signal Ratio\n",
    "ES_ratio = \"Yes\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesbian-speech",
   "metadata": {
    "papermill": {
     "duration": 0.009967,
     "end_time": "2022-08-03T01:02:22.327092",
     "exception": false,
     "start_time": "2022-08-03T01:02:22.317125",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Arranging and Normalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "perceived-investor",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-03T01:02:22.351930Z",
     "iopub.status.busy": "2022-08-03T01:02:22.350877Z",
     "iopub.status.idle": "2022-08-03T01:02:24.923550Z",
     "shell.execute_reply": "2022-08-03T01:02:24.922584Z",
     "shell.execute_reply.started": "2022-08-03T00:54:46.880076Z"
    },
    "papermill": {
     "duration": 2.586205,
     "end_time": "2022-08-03T01:02:24.923755",
     "exception": false,
     "start_time": "2022-08-03T01:02:22.337550",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "tensor(89.) tensor(44.3000) tensor([2.0150e+03, 7.2300e+02, 1.6000e+03, 1.7870e+01, 1.8961e+04, 9.9000e+01,\n",
      "        1.3144e+05, 7.6700e+01, 2.1000e+03, 9.9000e+01, 1.4390e+01, 9.9000e+01,\n",
      "        5.0600e+01, 1.1576e+05, 1.2939e+09, 2.7200e+01, 2.8200e+01, 9.3600e-01,\n",
      "        2.0700e+01]) tensor([2.0000e+03, 1.0000e+00, 0.0000e+00, 1.0000e-02, 0.0000e+00, 2.0000e+00,\n",
      "        0.0000e+00, 2.0000e+00, 0.0000e+00, 3.0000e+00, 7.4000e-01, 4.0000e+00,\n",
      "        1.0000e-01, 1.6813e+00, 3.4000e+01, 1.0000e-01, 1.0000e-01, 0.0000e+00,\n",
      "        4.5000e+00])\n",
      "tensor([1.5000e+01, 7.2200e+02, 1.6000e+03, 1.7860e+01, 1.8961e+04, 9.7000e+01,\n",
      "        1.3144e+05, 7.4700e+01, 2.1000e+03, 9.6000e+01, 1.3650e+01, 9.5000e+01,\n",
      "        5.0500e+01, 1.1576e+05, 1.2939e+09, 2.7100e+01, 2.8100e+01, 9.3600e-01,\n",
      "        1.6200e+01]) tensor(44.7000)\n"
     ]
    }
   ],
   "source": [
    "input_=[]\n",
    "output_=[]\n",
    "i_val=[]\n",
    "o_val=[]\n",
    "i_test=[]\n",
    "o_test=[]\n",
    "i_all =[]\n",
    "o_all=[]\n",
    "iter1=0\n",
    "\n",
    "for row in df.iloc:\n",
    "    i_all.append((row[0:len(row)-1]).astype(float))\n",
    "    o_all.append(row[-1])\n",
    "    if iter1%10 >1:\n",
    "        input_.append((row[0:len(row)-1]).astype(float))\n",
    "        output_.append(row[-1])\n",
    "    if iter1%10 ==0:\n",
    "        i_val.append((row[0:len(row)-1]).astype(float))\n",
    "        o_val.append(row[-1])\n",
    "    if iter1%10 ==1:\n",
    "        i_test.append((row[0:len(row)-1]).astype(float))\n",
    "        o_test.append(row[-1])\n",
    "    iter1 = iter1 + 1\n",
    "  \n",
    "\n",
    "    \n",
    "num_input = len(row)-1;\n",
    "print(num_input)\n",
    "\n",
    "####################################################\n",
    "#\n",
    "# This code is written with the help of the demo:\n",
    "# https://medium.com/@benjamin.phillips22/simple-regression-with-neural-networks-in-pytorch-313f06910379\n",
    "#\n",
    "####################################################\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import imageio\n",
    "\n",
    "torch.manual_seed(1)    # reproducible\n",
    "\n",
    "x = torch.tensor(input_).float()  \n",
    "y = torch.tensor(output_).float()   \n",
    "new_shape = (len(y), 1)\n",
    "y = y.view(new_shape)\n",
    "\n",
    "\n",
    "i_val = torch.tensor(i_val).float()  \n",
    "o_val = torch.tensor(o_val).float()   \n",
    "new_shape = (len(o_val), 1)\n",
    "o_val = o_val.view(new_shape)\n",
    "\n",
    "\n",
    "\n",
    "max_y = torch.max(y[:,0])\n",
    "min_y =torch.min(y[:,0])\n",
    "\n",
    "max_x = torch.max(x,dim=0)\n",
    "min_x = torch.min(x,dim=0)\n",
    "\n",
    "print(max_y, min_y, max_x.values, min_x.values)\n",
    "\n",
    "range_y = max_y - min_y\n",
    "range_x = max_x.values - min_x.values\n",
    "\n",
    "print(range_x, range_y)\n",
    "\n",
    "    #Normalizing\n",
    "x = (x - min_x.values)/range_x\n",
    "y = (y - min_y)/range_y\n",
    "\n",
    "    #Normalizing\n",
    "i_val = (i_val - min_x.values)/range_x\n",
    "o_val = (o_val - min_y)/range_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "italic-telling",
   "metadata": {
    "papermill": {
     "duration": 0.012309,
     "end_time": "2022-08-03T01:02:24.948628",
     "exception": false,
     "start_time": "2022-08-03T01:02:24.936319",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Prediction NN Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "separate-marble",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-03T01:02:24.984304Z",
     "iopub.status.busy": "2022-08-03T01:02:24.983583Z",
     "iopub.status.idle": "2022-08-03T01:02:39.656453Z",
     "shell.execute_reply": "2022-08-03T01:02:39.656973Z",
     "shell.execute_reply.started": "2022-08-03T00:54:47.754208Z"
    },
    "papermill": {
     "duration": 14.696622,
     "end_time": "2022-08-03T01:02:39.657190",
     "exception": false,
     "start_time": "2022-08-03T01:02:24.960568",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (hidden): Linear(in_features=19, out_features=500, bias=True)\n",
      "  (hidden2): Linear(in_features=500, out_features=500, bias=True)\n",
      "  (predict): Linear(in_features=500, out_features=1, bias=True)\n",
      ")\n",
      "Epoch [200/600], Loss: 0.0182, Minimum Loss 0.018225, Val Loss 0.019159  \n",
      "Epoch [400/600], Loss: 0.0101, Minimum Loss 0.010058, Val Loss 0.010342  \n",
      "Epoch [600/600], Loss: 0.0072, Minimum Loss 0.007196, Val Loss 0.007345  \n"
     ]
    }
   ],
   "source": [
    "# torch can only train on Variable, so convert them to Variable\n",
    "x, y = Variable(x), Variable(y)\n",
    " \n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, n_feature, n_hidden, n_output):\n",
    "        super(Net, self).__init__()\n",
    "        self.hidden = torch.nn.Linear(n_feature, n_hidden)   # hidden layer\n",
    "        self.hidden2 = torch.nn.Linear(n_hidden, n_hidden)   # hidden layer\n",
    "        self.predict = torch.nn.Linear(n_hidden, n_output)   # output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.hidden(x))      # activation function for hidden layer\n",
    "        x = F.relu(self.hidden2(x))\n",
    "        x = self.predict(x)             # linear output\n",
    "        return x\n",
    "\n",
    "# use the same net as before      \n",
    "net = Net(n_feature=num_input, n_hidden=500, n_output=1)     # define the network\n",
    "print(net)  # net architecture\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.05)\n",
    "loss_func = torch.nn.MSELoss()  # this is for regression mean squared loss\n",
    "\n",
    "\n",
    "minimum_train_loss = 1e5 #High initial values\n",
    "minimum_val_loss = 1e5\n",
    "EPOCH = 600\n",
    "\n",
    "# start training\n",
    "for epoch in range(EPOCH):\n",
    "  \n",
    "    prediction = net(x)     # input x and predict based on x\n",
    "\n",
    "    loss = loss_func(prediction, y)     # must be (1. nn output, 2. target)\n",
    "\n",
    "    optimizer.zero_grad()   # clear gradients for next train\n",
    "    loss.backward()         # backpropagation, compute gradients\n",
    "    optimizer.step()        # apply gradients\n",
    "    \n",
    "    if loss<minimum_train_loss:\n",
    "        minimum_train_loss =loss\n",
    "        net_opt = net\n",
    "    \n",
    "    if epoch%200 == 199:\n",
    "      prediction = net_opt(i_val)\n",
    "      loss_val = loss_func(prediction, o_val)\n",
    "      if loss_val<minimum_val_loss:\n",
    "        minimum_val_loss = loss_val\n",
    "        net_opt_val = net_opt\n",
    "      print (\"Epoch [{}/{}], Loss: {:.4f}, Minimum Loss {:.6f}, Val Loss {:.6f}  \"  .format(epoch+1, EPOCH, loss, minimum_train_loss, minimum_val_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sharp-lindsay",
   "metadata": {
    "papermill": {
     "duration": 0.013665,
     "end_time": "2022-08-03T01:02:39.683488",
     "exception": false,
     "start_time": "2022-08-03T01:02:39.669823",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Computing Test Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "hidden-figure",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-03T01:02:39.712073Z",
     "iopub.status.busy": "2022-08-03T01:02:39.711048Z",
     "iopub.status.idle": "2022-08-03T01:02:39.735430Z",
     "shell.execute_reply": "2022-08-03T01:02:39.736038Z",
     "shell.execute_reply.started": "2022-08-03T00:55:03.124462Z"
    },
    "papermill": {
     "duration": 0.040532,
     "end_time": "2022-08-03T01:02:39.736260",
     "exception": false,
     "start_time": "2022-08-03T01:02:39.695728",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized Test Loss 0.0071752337\n",
      "Test Loss 14.336763\n"
     ]
    }
   ],
   "source": [
    " \n",
    "i_test, o_test = Variable(torch.tensor(i_test)).float(), Variable(torch.tensor(o_test).float())\n",
    "new_shape = (len(o_test), 1)\n",
    "o_test = o_test.view(new_shape)\n",
    "\n",
    "    #Normalizing\n",
    "i_test = (i_test - min_x.values)/range_x\n",
    "o_test = (o_test - min_y)/range_y\n",
    "\n",
    "prediction = net_opt_val(i_test)\n",
    "loss_test = loss_func(prediction, o_test)\n",
    "\n",
    "print(\"Normalized Test Loss\",loss_test.detach().numpy())\n",
    "\n",
    "loss_test = loss_test*range_y*range_y # As the loss function returns MSE\n",
    "\n",
    "print(\"Test Loss\",loss_test.detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "built-blake",
   "metadata": {
    "papermill": {
     "duration": 0.013063,
     "end_time": "2022-08-03T01:02:39.763615",
     "exception": false,
     "start_time": "2022-08-03T01:02:39.750552",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# NN for Predicting Heteroscedastic Absolute Error of Previous NN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "lasting-civilian",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-03T01:02:39.792710Z",
     "iopub.status.busy": "2022-08-03T01:02:39.791939Z",
     "iopub.status.idle": "2022-08-03T01:02:55.297273Z",
     "shell.execute_reply": "2022-08-03T01:02:55.296088Z",
     "shell.execute_reply.started": "2022-08-03T00:55:03.152242Z"
    },
    "papermill": {
     "duration": 15.521249,
     "end_time": "2022-08-03T01:02:55.297525",
     "exception": false,
     "start_time": "2022-08-03T01:02:39.776276",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (hidden): Linear(in_features=19, out_features=500, bias=True)\n",
      "  (hidden2): Linear(in_features=500, out_features=500, bias=True)\n",
      "  (predict): Linear(in_features=500, out_features=1, bias=True)\n",
      ")\n",
      "Error to Signal ratio: tensor(0.0749)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:446: UserWarning: Using a target size (torch.Size([1319])) that is different to the input size (torch.Size([1319, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [200/600], Loss: 0.0029, Minimum Loss 0.002879, Val Loss 0.275328  \n",
      "Epoch [400/600], Loss: 0.0029, Minimum Loss 0.002879, Val Loss 0.275328  \n",
      "Epoch [600/600], Loss: 0.0029, Minimum Loss 0.002879, Val Loss 0.275328  \n"
     ]
    }
   ],
   "source": [
    "y_e = torch.zeros(len(x), dtype=torch.float) # initializing a variable of that size\n",
    "\n",
    "for iter1 in range(len(x)):\n",
    "    current_input = x[iter1,:];\n",
    "    current_output = net_opt_val(current_input);\n",
    "    y_e[iter1] = torch.abs(current_output - y[iter1]) \n",
    "        \n",
    "x, y_e = Variable(x), Variable(y_e)\n",
    "net_e = Net(n_feature=num_input, n_hidden=500, n_output=1)     # define the network\n",
    "print(net_e)  # net architecture\n",
    "\n",
    "# Error to Signal ratio\n",
    "ratio_e_s = 0.5 #default\n",
    "if ES_ratio == \"Yes\":\n",
    "    ratio_e_s = torch.var(y_e)/torch.var(y)\n",
    "\n",
    "    \n",
    "print('Error to Signal ratio:', ratio_e_s)\n",
    "\n",
    "optimizer = torch.optim.Adam(net_e.parameters(), lr=0.05)\n",
    "\n",
    "minimum_train_loss = 1e5 #High initial values\n",
    "minimum_val_loss = 1e5\n",
    "EPOCH = 600\n",
    "\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "  \n",
    "    prediction = net_e(x)     # input x and predict based on x\n",
    "\n",
    "    loss = loss_func(prediction, y_e)     # must be (1. nn output, 2. target)\n",
    "\n",
    "    optimizer.zero_grad()   # clear gradients for next train\n",
    "    loss.backward()         # backpropagation, compute gradients\n",
    "    optimizer.step()        # apply gradients\n",
    "    \n",
    "    if loss<minimum_train_loss:\n",
    "        minimum_train_loss =loss\n",
    "        net_opt = net_e\n",
    "    \n",
    "    if epoch%200 == 199:\n",
    "      prediction = net_opt(i_val)\n",
    "      loss_val = loss_func(prediction, o_val)\n",
    "      if loss_val<minimum_val_loss:\n",
    "        minimum_val_loss = loss_val\n",
    "        net_opt_val_e = net_opt\n",
    "      print (\"Epoch [{}/{}], Loss: {:.4f}, Minimum Loss {:.6f}, Val Loss {:.6f}  \"  .format(epoch+1, EPOCH, loss, minimum_train_loss, minimum_val_loss))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handy-polyester",
   "metadata": {
    "papermill": {
     "duration": 0.014732,
     "end_time": "2022-08-03T01:02:55.327272",
     "exception": false,
     "start_time": "2022-08-03T01:02:55.312540",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Minimim deviation based similarity finding for Uncertainty Bounds\n",
    "\n",
    "   Aim: To achieve all indexes of similar samples\n",
    "\n",
    "   Steps: \n",
    "\n",
    "1. Itertion over all Input combinations.\n",
    "\n",
    "2. Find all deviation by indexes \n",
    "   (sensitivity can be considered during the consideration of deviation)\n",
    "\n",
    "3. Save top 100 similar events\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "satellite-prophet",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-03T01:02:55.377514Z",
     "iopub.status.busy": "2022-08-03T01:02:55.376450Z",
     "iopub.status.idle": "2022-08-03T01:05:42.091144Z",
     "shell.execute_reply": "2022-08-03T01:05:42.090569Z",
     "shell.execute_reply.started": "2022-08-03T00:55:20.568597Z"
    },
    "papermill": {
     "duration": 166.749307,
     "end_time": "2022-08-03T01:05:42.091310",
     "exception": false,
     "start_time": "2022-08-03T01:02:55.342003",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.064281382656155 %  Complete\n",
      "36.38568829593693 %  Complete\n",
      "66.7070952092177 %  Complete\n",
      "97.02850212249848 %  Complete\n",
      "100% Complete in 2m 34s\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pickle as pkl\n",
    "import time\n",
    "\n",
    "\n",
    "x = torch.tensor(i_all).float()  \n",
    "y = torch.tensor(o_all).float()   \n",
    "new_shape = (len(y), 1)\n",
    "y = y.view(new_shape)\n",
    "x = (x - min_x.values)/range_x\n",
    "y = (y - min_y)/range_y\n",
    "x, y = Variable(x), Variable(y)\n",
    "\n",
    "\n",
    "max_dev_index = np.zeros(shape=(len(x),2))\n",
    "Similarity = np.zeros(shape=(len(x),Similar_event_count+1))\n",
    "sensitivity = torch.ones(len(max_x.values), dtype=torch.float64) # just initializing a variable of that size\n",
    "error_sensitivity = torch.ones(len(max_x.values), dtype=torch.float64)\n",
    "iter_debug = 0\n",
    "since = time.time()\n",
    "\n",
    "for iter1 in range(len(x)):\n",
    "    current_input = x[iter1,:];\n",
    "    \n",
    "    # While considering only Sensitivity\n",
    "    if sensitivity_consideration == 1 and error_sensitivity_consideration ==0:\n",
    "        current_output = net_opt_val(current_input)\n",
    "        \n",
    "       # Determining Sensitivity near input[iter1]\n",
    "        for iter2 in range(len(current_input)): \n",
    "            current_input[iter2] = current_input[iter2] + range_x[iter2]/1e4\n",
    "            \n",
    "            sensitivity[iter2] = torch.abs(current_output - net_opt_val(current_input))\n",
    "            \n",
    "            current_input[iter2] = current_input[iter2] - range_x[iter2]/1e4\n",
    "        \n",
    "        sensitivity = sensitivity/torch.max(sensitivity)\n",
    "        #The highest sensitivity is considered one\n",
    "    \n",
    "    if sensitivity_consideration == 1 and error_sensitivity_consideration ==1:\n",
    "        current_output = net_opt_val(current_input)\n",
    "        current_error = net_opt_val_e(current_input)\n",
    "        # ratio, ratio_e_s= 0.5 while giving equal concentration to error and signal\n",
    "        \n",
    "       # Determining Sensitivity and Error Sensitivity near input[iter1]\n",
    "        for iter2 in range(len(current_input)): \n",
    "            current_input[iter2] = current_input[iter2] + range_x[iter2]/1e4\n",
    "            \n",
    "            sensitivity[iter2] = torch.abs(current_output - net_opt_val(current_input))\n",
    "            error_sensitivity[iter2] = torch.abs(current_error - net_opt_val_e(current_input))\n",
    "            \n",
    "            current_input[iter2] = current_input[iter2] - range_x[iter2]/1e4\n",
    "        \n",
    "        sensitivity = sensitivity/torch.max(sensitivity)*(1-ratio_e_s)\n",
    "        error_sensitivity = error_sensitivity/torch.max(error_sensitivity)* ratio_e_s\n",
    "        sensitivity = sensitivity + error_sensitivity\n",
    "        \n",
    "        #The highest sensitivity is considered half for each, then adding\n",
    "        \n",
    "    \n",
    "    for iter2 in range(len(x)):\n",
    "        max_dev_index[iter2][0] = torch.max(sensitivity*torch.abs(current_input-x[iter2,:])/range_x).detach().numpy()\n",
    "        max_dev_index[iter2][1] = iter2\n",
    "        \n",
    "    sort_dev_index = max_dev_index[np.argsort(max_dev_index[:, 0])]\n",
    "    Similarity_threshold = sort_dev_index[Similar_event_count][0]\n",
    "    matched_indexes = sort_dev_index[0:Similar_event_count,1]\n",
    "    \n",
    "    Similarity[iter1,0] = Similarity_threshold\n",
    "    Similarity[iter1,1:(Similar_event_count+1)] = matched_indexes\n",
    "    \n",
    "    if iter1%500==100:   \n",
    "        print(iter1/len(x)*100, '%' '  Complete')\n",
    "        time_elapsed = time.time() - since\n",
    "        # Observing progres in Command Window\n",
    "        # May Take about hours to find all similar events for entire training data\n",
    "\n",
    "print('100% Complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))    \n",
    "\n",
    "fileName = './' + 'Similarity'\n",
    "fileObject = open(fileName, 'wb')\n",
    "\n",
    "pkl.dump(Similarity, fileObject)\n",
    "fileObject.close()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 210.009358,
   "end_time": "2022-08-03T01:05:45.425249",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-08-03T01:02:15.415891",
   "version": "2.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
