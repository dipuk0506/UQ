{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "tested-texture",
   "metadata": {
    "papermill": {
     "duration": 0.011765,
     "end_time": "2022-08-11T04:43:30.774967",
     "exception": false,
     "start_time": "2022-08-11T04:43:30.763202",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "recent-intellectual",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-11T04:43:30.802487Z",
     "iopub.status.busy": "2022-08-11T04:43:30.800418Z",
     "iopub.status.idle": "2022-08-11T04:43:30.863912Z",
     "shell.execute_reply": "2022-08-11T04:43:30.865162Z",
     "shell.execute_reply.started": "2022-05-09T06:10:29.544546Z"
    },
    "papermill": {
     "duration": 0.079523,
     "end_time": "2022-08-11T04:43:30.865476",
     "exception": false,
     "start_time": "2022-08-11T04:43:30.785953",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input1</th>\n",
       "      <th>Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.037112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001257</td>\n",
       "      <td>0.005684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002513</td>\n",
       "      <td>-0.017941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.003770</td>\n",
       "      <td>0.020993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005027</td>\n",
       "      <td>-0.016084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Input1    Output\n",
       "0  0.000000  0.037112\n",
       "1  0.001257  0.005684\n",
       "2  0.002513 -0.017941\n",
       "3  0.003770  0.020993\n",
       "4  0.005027 -0.016084"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_csv_path = '../input/toy-dataset-for-regression-and-uq/Data1_Train.csv'\n",
    "test_csv_path = '../input/toy-dataset-for-regression-and-uq/Data1_Test.csv'\n",
    "val_csv_path = '../input/toy-dataset-for-regression-and-uq/Data1_Val.csv'\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "train_df = pd.read_csv(train_csv_path)\n",
    "val_df = pd.read_csv(val_csv_path)\n",
    "train_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outside-writing",
   "metadata": {
    "papermill": {
     "duration": 0.009976,
     "end_time": "2022-08-11T04:43:30.886036",
     "exception": false,
     "start_time": "2022-08-11T04:43:30.876060",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Considerations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "intense-alberta",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-11T04:43:30.912302Z",
     "iopub.status.busy": "2022-08-11T04:43:30.911239Z",
     "iopub.status.idle": "2022-08-11T04:43:30.913679Z",
     "shell.execute_reply": "2022-08-11T04:43:30.914237Z",
     "shell.execute_reply.started": "2022-05-09T06:10:29.617524Z"
    },
    "papermill": {
     "duration": 0.018245,
     "end_time": "2022-08-11T04:43:30.914434",
     "exception": false,
     "start_time": "2022-08-11T04:43:30.896189",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Similar_event_count = 100\n",
    "sensitivity_consideration = 1\n",
    "error_sensitivity_consideration = 1\n",
    "\n",
    "# Error-Signal Ratio\n",
    "ES_ratio = \"Yes\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occasional-divorce",
   "metadata": {
    "papermill": {
     "duration": 0.010424,
     "end_time": "2022-08-11T04:43:30.935127",
     "exception": false,
     "start_time": "2022-08-11T04:43:30.924703",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Arranging and Normalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "civil-automation",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-11T04:43:30.959043Z",
     "iopub.status.busy": "2022-08-11T04:43:30.958306Z",
     "iopub.status.idle": "2022-08-11T04:43:34.267904Z",
     "shell.execute_reply": "2022-08-11T04:43:34.268678Z",
     "shell.execute_reply.started": "2022-05-09T06:10:29.623849Z"
    },
    "papermill": {
     "duration": 3.323623,
     "end_time": "2022-08-11T04:43:34.268919",
     "exception": false,
     "start_time": "2022-08-11T04:43:30.945296",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "tensor(1.0487) tensor(-1.0480) tensor([6.2819]) tensor([0.])\n",
      "tensor([6.2819]) tensor(2.0967)\n"
     ]
    }
   ],
   "source": [
    "input_=[]\n",
    "output_=[]\n",
    "for row in train_df.iloc:\n",
    "    input_.append((row[0:len(row)-1]).astype(float))\n",
    "    output_.append(row[-1])\n",
    "    \n",
    "i_val=[]\n",
    "o_val=[]\n",
    "for row in val_df.iloc:\n",
    "    i_val.append((row[0:len(row)-1]).astype(float))\n",
    "    o_val.append(row[-1])\n",
    "    \n",
    "num_input = len(row)-1;\n",
    "print(num_input)\n",
    "\n",
    "####################################################\n",
    "#\n",
    "# This code is written with the help of the demo:\n",
    "# https://medium.com/@benjamin.phillips22/simple-regression-with-neural-networks-in-pytorch-313f06910379\n",
    "#\n",
    "####################################################\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import imageio\n",
    "\n",
    "torch.manual_seed(1)    # reproducible\n",
    "\n",
    "x = torch.tensor(input_).float()  \n",
    "y = torch.tensor(output_).float()   \n",
    "new_shape = (len(y), 1)\n",
    "y = y.view(new_shape)\n",
    "\n",
    "\n",
    "i_val = torch.tensor(i_val).float()  \n",
    "o_val = torch.tensor(o_val).float()   \n",
    "new_shape = (len(o_val), 1)\n",
    "o_val = o_val.view(new_shape)\n",
    "\n",
    "\n",
    "\n",
    "max_y = torch.max(y[:,0])\n",
    "min_y =torch.min(y[:,0])\n",
    "\n",
    "max_x = torch.max(x,dim=0)\n",
    "min_x = torch.min(x,dim=0)\n",
    "\n",
    "print(max_y, min_y, max_x.values, min_x.values)\n",
    "\n",
    "range_y = max_y - min_y\n",
    "range_x = max_x.values - min_x.values\n",
    "\n",
    "print(range_x, range_y)\n",
    "\n",
    "    #Normalizing\n",
    "x = (x - min_x.values)/range_x\n",
    "y = (y - min_y)/range_y\n",
    "\n",
    "    #Normalizing\n",
    "i_val = (i_val - min_x.values)/range_x\n",
    "o_val = (o_val - min_y)/range_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worst-flower",
   "metadata": {
    "papermill": {
     "duration": 0.01052,
     "end_time": "2022-08-11T04:43:34.291382",
     "exception": false,
     "start_time": "2022-08-11T04:43:34.280862",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Prediction NN Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "declared-demonstration",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-11T04:43:34.316594Z",
     "iopub.status.busy": "2022-08-11T04:43:34.315924Z",
     "iopub.status.idle": "2022-08-11T04:44:21.423313Z",
     "shell.execute_reply": "2022-08-11T04:44:21.422388Z",
     "shell.execute_reply.started": "2022-05-09T06:10:32.486056Z"
    },
    "papermill": {
     "duration": 47.120812,
     "end_time": "2022-08-11T04:44:21.423486",
     "exception": false,
     "start_time": "2022-08-11T04:43:34.302674",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (hidden): Linear(in_features=1, out_features=500, bias=True)\n",
      "  (hidden2): Linear(in_features=500, out_features=500, bias=True)\n",
      "  (predict): Linear(in_features=500, out_features=1, bias=True)\n",
      ")\n",
      "Epoch [200/600], Loss: 0.0048, Minimum Loss 0.001731, Val Loss 0.002448  \n",
      "Epoch [400/600], Loss: 0.0004, Minimum Loss 0.000445, Val Loss 0.000435  \n",
      "Epoch [600/600], Loss: 0.0002, Minimum Loss 0.000241, Val Loss 0.000232  \n"
     ]
    }
   ],
   "source": [
    "# torch can only train on Variable, so convert them to Variable\n",
    "x, y = Variable(x), Variable(y)\n",
    " \n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, n_feature, n_hidden, n_output):\n",
    "        super(Net, self).__init__()\n",
    "        self.hidden = torch.nn.Linear(n_feature, n_hidden)   # hidden layer\n",
    "        self.hidden2 = torch.nn.Linear(n_hidden, n_hidden)   # hidden layer\n",
    "        self.predict = torch.nn.Linear(n_hidden, n_output)   # output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.hidden(x))      # activation function for hidden layer\n",
    "        x = F.relu(self.hidden2(x))\n",
    "        x = self.predict(x)             # linear output\n",
    "        return x\n",
    "\n",
    "# use the same net as before      \n",
    "net = Net(n_feature=num_input, n_hidden=500, n_output=1)     # define the network\n",
    "print(net)  # net architecture\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.05)\n",
    "loss_func = torch.nn.MSELoss()  # this is for regression mean squared loss\n",
    "\n",
    "\n",
    "minimum_train_loss = 1e5 #High initial values\n",
    "minimum_val_loss = 1e5\n",
    "EPOCH = 600\n",
    "\n",
    "# start training\n",
    "for epoch in range(EPOCH):\n",
    "  \n",
    "    prediction = net(x)     # input x and predict based on x\n",
    "\n",
    "    loss = loss_func(prediction, y)     # must be (1. nn output, 2. target)\n",
    "\n",
    "    optimizer.zero_grad()   # clear gradients for next train\n",
    "    loss.backward()         # backpropagation, compute gradients\n",
    "    optimizer.step()        # apply gradients\n",
    "    \n",
    "    if loss<minimum_train_loss:\n",
    "        minimum_train_loss =loss\n",
    "        net_opt = net\n",
    "    \n",
    "    if epoch%200 == 199:\n",
    "      prediction = net_opt(i_val)\n",
    "      loss_val = loss_func(prediction, o_val)\n",
    "      if loss_val<minimum_val_loss:\n",
    "        minimum_val_loss = loss_val\n",
    "        net_opt_val = net_opt\n",
    "      print (\"Epoch [{}/{}], Loss: {:.4f}, Minimum Loss {:.6f}, Val Loss {:.6f}  \"  .format(epoch+1, EPOCH, loss, minimum_train_loss, minimum_val_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automatic-spoke",
   "metadata": {
    "papermill": {
     "duration": 0.012575,
     "end_time": "2022-08-11T04:44:21.448447",
     "exception": false,
     "start_time": "2022-08-11T04:44:21.435872",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Computing Test Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "frank-swaziland",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-11T04:44:21.481113Z",
     "iopub.status.busy": "2022-08-11T04:44:21.480397Z",
     "iopub.status.idle": "2022-08-11T04:44:21.986535Z",
     "shell.execute_reply": "2022-08-11T04:44:21.986000Z",
     "shell.execute_reply.started": "2022-05-09T06:11:15.531431Z"
    },
    "papermill": {
     "duration": 0.52607,
     "end_time": "2022-08-11T04:44:21.986720",
     "exception": false,
     "start_time": "2022-08-11T04:44:21.460650",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized Test Loss 0.0002564186\n",
      "Test Loss 0.0011272473\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv(test_csv_path)\n",
    "\n",
    "i_test=[]\n",
    "o_test=[]\n",
    "for row in test_df.iloc:\n",
    "    i_test.append((row[0:len(row)-1]).astype(float))\n",
    "    o_test.append(row[-1])\n",
    "\n",
    "\n",
    "   \n",
    "i_test, o_test = Variable(torch.tensor(i_test)).float(), Variable(torch.tensor(o_test).float())\n",
    "new_shape = (len(o_test), 1)\n",
    "o_test = o_test.view(new_shape)\n",
    "\n",
    "    #Normalizing\n",
    "i_test = (i_test - min_x.values)/range_x\n",
    "o_test = (o_test - min_y)/range_y\n",
    "\n",
    "prediction = net_opt_val(i_test)\n",
    "loss_test = loss_func(prediction, o_test)\n",
    "\n",
    "print(\"Normalized Test Loss\",loss_test.detach().numpy())\n",
    "\n",
    "loss_test = loss_test*range_y*range_y # As the loss function returns MSE\n",
    "\n",
    "print(\"Test Loss\",loss_test.detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assured-korea",
   "metadata": {
    "papermill": {
     "duration": 0.011844,
     "end_time": "2022-08-11T04:44:22.011210",
     "exception": false,
     "start_time": "2022-08-11T04:44:21.999366",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# NN for Predicting Heteroscedastic Absolute Error of Previous NN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "detailed-canberra",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-11T04:44:22.045934Z",
     "iopub.status.busy": "2022-08-11T04:44:22.045032Z",
     "iopub.status.idle": "2022-08-11T04:46:17.010154Z",
     "shell.execute_reply": "2022-08-11T04:46:17.010879Z"
    },
    "papermill": {
     "duration": 114.987801,
     "end_time": "2022-08-11T04:46:17.011119",
     "exception": false,
     "start_time": "2022-08-11T04:44:22.023318",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (hidden): Linear(in_features=1, out_features=500, bias=True)\n",
      "  (hidden2): Linear(in_features=500, out_features=500, bias=True)\n",
      "  (predict): Linear(in_features=500, out_features=1, bias=True)\n",
      ")\n",
      "Error to Signal ratio: tensor(0.0006)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:446: UserWarning: Using a target size (torch.Size([5000])) that is different to the input size (torch.Size([5000, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [200/600], Loss: 0.0001, Minimum Loss 0.000084, Val Loss 0.352386  \n",
      "Epoch [400/600], Loss: 0.0001, Minimum Loss 0.000073, Val Loss 0.351395  \n",
      "Epoch [600/600], Loss: 0.0001, Minimum Loss 0.000072, Val Loss 0.351059  \n"
     ]
    }
   ],
   "source": [
    "y_e = torch.zeros(len(x), dtype=torch.float) # initializing a variable of that size\n",
    "\n",
    "for iter1 in range(len(x)):\n",
    "    current_input = x[iter1,:];\n",
    "    current_output = net_opt_val(current_input);\n",
    "    y_e[iter1] = torch.abs(current_output - y[iter1]) \n",
    "        \n",
    "x, y_e = Variable(x), Variable(y_e)\n",
    "net_e = Net(n_feature=num_input, n_hidden=500, n_output=1)     # define the network\n",
    "print(net_e)  # net architecture\n",
    "\n",
    "# Error to Signal ratio\n",
    "ratio_e_s = 0.5 #default\n",
    "if ES_ratio == \"Yes\":\n",
    "    ratio_e_s = torch.var(y_e)/torch.var(y)\n",
    "\n",
    "    \n",
    "print('Error to Signal ratio:', ratio_e_s)\n",
    "\n",
    "optimizer = torch.optim.Adam(net_e.parameters(), lr=0.05)\n",
    "\n",
    "minimum_train_loss = 1e5 #High initial values\n",
    "minimum_val_loss = 1e5\n",
    "EPOCH = 600\n",
    "\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "  \n",
    "    prediction = net_e(x)     # input x and predict based on x\n",
    "\n",
    "    loss = loss_func(prediction, y_e)     # must be (1. nn output, 2. target)\n",
    "\n",
    "    optimizer.zero_grad()   # clear gradients for next train\n",
    "    loss.backward()         # backpropagation, compute gradients\n",
    "    optimizer.step()        # apply gradients\n",
    "    \n",
    "    if loss<minimum_train_loss:\n",
    "        minimum_train_loss =loss\n",
    "        net_opt = net_e\n",
    "    \n",
    "    if epoch%200 == 199:\n",
    "      prediction = net_opt(i_val)\n",
    "      loss_val = loss_func(prediction, o_val)\n",
    "      if loss_val<minimum_val_loss:\n",
    "        minimum_val_loss = loss_val\n",
    "        net_opt_val_e = net_opt\n",
    "      print (\"Epoch [{}/{}], Loss: {:.4f}, Minimum Loss {:.6f}, Val Loss {:.6f}  \"  .format(epoch+1, EPOCH, loss, minimum_train_loss, minimum_val_loss))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlike-nashville",
   "metadata": {
    "papermill": {
     "duration": 0.013503,
     "end_time": "2022-08-11T04:46:17.038850",
     "exception": false,
     "start_time": "2022-08-11T04:46:17.025347",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Minimim deviation based similarity finding for Uncertainty Bounds\n",
    "\n",
    "   Aim: To achieve all indexes of similar samples\n",
    "\n",
    "   Steps: \n",
    "\n",
    "1. Itertion over all Input combinations.\n",
    "\n",
    "2. Find all deviation by indexes \n",
    "   (sensitivity can be considered during the consideration of deviation)\n",
    "\n",
    "3. Save top 100 similar events\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "derived-concentration",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-11T04:46:17.081631Z",
     "iopub.status.busy": "2022-08-11T04:46:17.077190Z",
     "iopub.status.idle": "2022-08-11T05:07:00.072529Z",
     "shell.execute_reply": "2022-08-11T05:07:00.073079Z"
    },
    "papermill": {
     "duration": 1243.020536,
     "end_time": "2022-08-11T05:07:00.073282",
     "exception": false,
     "start_time": "2022-08-11T04:46:17.052746",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0 %  Complete\n",
      "22.0 %  Complete\n",
      "42.0 %  Complete\n",
      "62.0 %  Complete\n",
      "82.0 %  Complete\n",
      "100% Complete in 16m 55s\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pickle as pkl\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "max_dev_index = np.zeros(shape=(len(x),2))\n",
    "Similarity = np.zeros(shape=(len(x),Similar_event_count+1))\n",
    "sensitivity = torch.ones(len(max_x.values), dtype=torch.float64) # just initializing a variable of that size\n",
    "error_sensitivity = torch.ones(len(max_x.values), dtype=torch.float64)\n",
    "iter_debug = 0\n",
    "since = time.time()\n",
    "\n",
    "for iter1 in range(len(x)):\n",
    "    current_input = x[iter1,:];\n",
    "    \n",
    "    # While considering only Sensitivity\n",
    "    if sensitivity_consideration == 1 and error_sensitivity_consideration ==0:\n",
    "        current_output = net_opt_val(current_input)\n",
    "        \n",
    "       # Determining Sensitivity near input[iter1]\n",
    "        for iter2 in range(len(current_input)): \n",
    "            current_input[iter2] = current_input[iter2] + range_x[iter2]/1e4\n",
    "            \n",
    "            sensitivity[iter2] = torch.abs(current_output - net_opt_val(current_input))\n",
    "            \n",
    "            current_input[iter2] = current_input[iter2] - range_x[iter2]/1e4\n",
    "        \n",
    "        sensitivity = sensitivity/torch.max(sensitivity)\n",
    "        #The highest sensitivity is considered one\n",
    "    \n",
    "    if sensitivity_consideration == 1 and error_sensitivity_consideration ==1:\n",
    "        current_output = net_opt_val(current_input)\n",
    "        current_error = net_opt_val_e(current_input)\n",
    "        # ratio, ratio_e_s= 0.5 while giving equal concentration to error and signal\n",
    "        \n",
    "       # Determining Sensitivity and Error Sensitivity near input[iter1]\n",
    "        for iter2 in range(len(current_input)): \n",
    "            current_input[iter2] = current_input[iter2] + range_x[iter2]/1e4\n",
    "            \n",
    "            sensitivity[iter2] = torch.abs(current_output - net_opt_val(current_input))\n",
    "            error_sensitivity[iter2] = torch.abs(current_error - net_opt_val_e(current_input))\n",
    "            \n",
    "            current_input[iter2] = current_input[iter2] - range_x[iter2]/1e4\n",
    "        \n",
    "        sensitivity = sensitivity/torch.max(sensitivity)*(1-ratio_e_s)\n",
    "        error_sensitivity = error_sensitivity/torch.max(error_sensitivity)* ratio_e_s\n",
    "        sensitivity = sensitivity + error_sensitivity\n",
    "        \n",
    "        #The highest sensitivity is considered half for each, then adding\n",
    "        \n",
    "    \n",
    "    for iter2 in range(len(x)):\n",
    "        max_dev_index[iter2][0] = torch.max(sensitivity*torch.abs(current_input-x[iter2,:])/range_x).detach().numpy()\n",
    "        max_dev_index[iter2][1] = iter2\n",
    "        \n",
    "    sort_dev_index = max_dev_index[np.argsort(max_dev_index[:, 0])]\n",
    "    Similarity_threshold = sort_dev_index[Similar_event_count][0]\n",
    "    matched_indexes = sort_dev_index[0:Similar_event_count,1]\n",
    "    \n",
    "    Similarity[iter1,0] = Similarity_threshold\n",
    "    Similarity[iter1,1:(Similar_event_count+1)] = matched_indexes\n",
    "    \n",
    "    if iter1%1000==100:   \n",
    "        print(iter1/len(x)*100, '%' '  Complete')\n",
    "        time_elapsed = time.time() - since\n",
    "        # Observing progres in Command Window\n",
    "        # May Take about hours to find all similar events for entire training data\n",
    "\n",
    "print('100% Complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))    \n",
    "\n",
    "fileName = './' + 'Similarity'\n",
    "fileObject = open(fileName, 'wb')\n",
    "\n",
    "pkl.dump(Similarity, fileObject)\n",
    "fileObject.close()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1417.152053,
   "end_time": "2022-08-11T05:07:01.802381",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-08-11T04:43:24.650328",
   "version": "2.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
