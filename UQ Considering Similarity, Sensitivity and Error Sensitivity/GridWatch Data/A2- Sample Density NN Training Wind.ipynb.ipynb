{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e8fee08",
   "metadata": {
    "papermill": {
     "duration": 0.008173,
     "end_time": "2022-08-08T06:44:31.846811",
     "exception": false,
     "start_time": "2022-08-08T06:44:31.838638",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f86b849",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-08T06:44:31.863671Z",
     "iopub.status.busy": "2022-08-08T06:44:31.863108Z",
     "iopub.status.idle": "2022-08-08T06:44:32.140785Z",
     "shell.execute_reply": "2022-08-08T06:44:32.139763Z"
    },
    "papermill": {
     "duration": 0.288706,
     "end_time": "2022-08-08T06:44:32.143422",
     "exception": false,
     "start_time": "2022-08-08T06:44:31.854716",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Similar Samples Considered 100\n",
      "Target Shape (20000,) Similar Samples Matrix Shape: (20000, 100)\n"
     ]
    }
   ],
   "source": [
    "import pickle as pkl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "fileName =  '../input/a1-data-to-similar-events/Similarity'\n",
    "fileObject2 = open(fileName, 'rb')\n",
    "Imported_data = pkl.load(fileObject2)\n",
    "fileObject2.close()\n",
    "\n",
    "#print('Similarity Thresholds:',Imported_data[:,0])\n",
    "\n",
    "#print('Most Similarity at:',Imported_data[:,1])\n",
    "\n",
    "Similar_event_count = len(Imported_data[0,:])-1\n",
    "print('Number of Similar Samples Considered', Similar_event_count)\n",
    "\n",
    "Similarity_thresholds = Imported_data[:,0]\n",
    "for iter1 in range(len(Similarity_thresholds)):\n",
    "    if Similarity_thresholds[iter1] < 1e15:\n",
    "        continue\n",
    "    Similarity_thresholds[iter1] = 1e15 # Avoiding NaN values \n",
    "    \n",
    "Sample_density = Similar_event_count/ Similarity_thresholds/ 100\n",
    "#Sample_density = number of samples with less than 1% (of range) deviation\n",
    "\n",
    "Similar_samples = Imported_data[:,1:Similar_event_count+1]\n",
    "\n",
    "print('Target Shape', Sample_density.shape, 'Similar Samples Matrix Shape:', Similar_samples.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c7c52ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-08T06:44:32.160210Z",
     "iopub.status.busy": "2022-08-08T06:44:32.159935Z",
     "iopub.status.idle": "2022-08-08T06:44:32.349938Z",
     "shell.execute_reply": "2022-08-08T06:44:32.349161Z"
    },
    "papermill": {
     "duration": 0.201073,
     "end_time": "2022-08-08T06:44:32.352329",
     "exception": false,
     "start_time": "2022-08-08T06:44:32.151256",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y(t-4)</th>\n",
       "      <th>y(t-3)</th>\n",
       "      <th>y(t-2)</th>\n",
       "      <th>y(t-1)</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Day</th>\n",
       "      <th>y(t)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1529.0</td>\n",
       "      <td>1561.0</td>\n",
       "      <td>1573.0</td>\n",
       "      <td>1559.0</td>\n",
       "      <td>16.835556</td>\n",
       "      <td>177.0</td>\n",
       "      <td>1565.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1561.0</td>\n",
       "      <td>1573.0</td>\n",
       "      <td>1559.0</td>\n",
       "      <td>1565.0</td>\n",
       "      <td>16.916944</td>\n",
       "      <td>177.0</td>\n",
       "      <td>1587.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1684.0</td>\n",
       "      <td>1695.0</td>\n",
       "      <td>1750.0</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>17.666944</td>\n",
       "      <td>177.0</td>\n",
       "      <td>1838.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1695.0</td>\n",
       "      <td>1750.0</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>1838.0</td>\n",
       "      <td>17.750556</td>\n",
       "      <td>177.0</td>\n",
       "      <td>1836.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1812.0</td>\n",
       "      <td>1805.0</td>\n",
       "      <td>1769.0</td>\n",
       "      <td>1758.0</td>\n",
       "      <td>18.500278</td>\n",
       "      <td>177.0</td>\n",
       "      <td>1773.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   y(t-4)  y(t-3)  y(t-2)  y(t-1)       Hour    Day    y(t)\n",
       "0  1529.0  1561.0  1573.0  1559.0  16.835556  177.0  1565.0\n",
       "1  1561.0  1573.0  1559.0  1565.0  16.916944  177.0  1587.0\n",
       "2  1684.0  1695.0  1750.0  1800.0  17.666944  177.0  1838.0\n",
       "3  1695.0  1750.0  1800.0  1838.0  17.750556  177.0  1836.0\n",
       "4  1812.0  1805.0  1769.0  1758.0  18.500278  177.0  1773.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_csv_path = '../input/electricity-uk-grid-data-preparation/Wind_train.csv'\n",
    "test_csv_path = '../input/electricity-uk-grid-data-preparation/Wind_test.csv'\n",
    "val_csv_path = '../input/electricity-uk-grid-data-preparation/Wind_val.csv'\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "train_df = pd.read_csv(train_csv_path)\n",
    "val_df = pd.read_csv(val_csv_path)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17942cb7",
   "metadata": {
    "papermill": {
     "duration": 0.007474,
     "end_time": "2022-08-08T06:44:32.367688",
     "exception": false,
     "start_time": "2022-08-08T06:44:32.360214",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training-Validation Splitting\n",
    "The training Dataset is split, as top matches and sample densities are computed on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2df512c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-08T06:44:32.385388Z",
     "iopub.status.busy": "2022-08-08T06:44:32.384524Z",
     "iopub.status.idle": "2022-08-08T06:44:38.034128Z",
     "shell.execute_reply": "2022-08-08T06:44:38.033160Z"
    },
    "papermill": {
     "duration": 5.660797,
     "end_time": "2022-08-08T06:44:38.036220",
     "exception": false,
     "start_time": "2022-08-08T06:44:32.375423",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "Shape of training input: torch.Size([4000, 6])\n",
      "Shape of validation input: torch.Size([1000, 6])\n",
      "tensor(3363934.) tensor(1.0000e-15) tensor([2843.0000, 2848.0000, 2848.0000, 2830.0000,   23.9206,  245.0000]) tensor([2.1000e+01, 2.2000e+01, 2.2000e+01, 2.2000e+01, 2.7778e-04, 1.7700e+02])\n",
      "tensor([2822.0000, 2826.0000, 2826.0000, 2808.0000,   23.9203,   68.0000]) tensor(3363934.)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "import imageio\n",
    "\n",
    "input_=[]\n",
    "output_=[]\n",
    "for row in train_df.iloc:\n",
    "    input_.append((row[0:len(row)-1]).astype(float))\n",
    "    output_.append(row[-1])\n",
    "    \n",
    "    \n",
    "num_input = len(row)-1;\n",
    "print(num_input)\n",
    "\n",
    "torch.manual_seed(1)    # reproducible\n",
    "\n",
    "x = torch.tensor(input_[0:4000]).float()  \n",
    "print('Shape of training input:',x.shape)\n",
    "y = torch.tensor(Sample_density[0:4000]).float()   \n",
    "new_shape = (len(y), 1)\n",
    "y = y.view(new_shape)\n",
    "\n",
    "\n",
    "i_val = torch.tensor(input_[4000:5000]).float()  \n",
    "print('Shape of validation input:',i_val.shape)\n",
    "o_val = torch.tensor(Sample_density[4000:5000]).float()   \n",
    "new_shape = (len(o_val), 1)\n",
    "o_val = o_val.view(new_shape)\n",
    "\n",
    "\n",
    "\n",
    "max_y = torch.max(y[:,0])\n",
    "min_y =torch.min(y[:,0])\n",
    "\n",
    "max_x = torch.max(x,dim=0)\n",
    "min_x = torch.min(x,dim=0)\n",
    "\n",
    "print(max_y, min_y, max_x.values, min_x.values)\n",
    "\n",
    "range_y = max_y - min_y\n",
    "range_x = max_x.values - min_x.values\n",
    "\n",
    "print(range_x, range_y)\n",
    "\n",
    "    #Normalizing\n",
    "x = (x - min_x.values)/range_x\n",
    "y = (y - min_y)/range_y\n",
    "\n",
    "i_val = (i_val - min_x.values)/range_x\n",
    "o_val = (o_val - min_y)/range_y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdd34ae",
   "metadata": {
    "papermill": {
     "duration": 0.010158,
     "end_time": "2022-08-08T06:44:38.055165",
     "exception": false,
     "start_time": "2022-08-08T06:44:38.045007",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Sample Density NN Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1496c21a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-08T06:44:38.081711Z",
     "iopub.status.busy": "2022-08-08T06:44:38.080903Z",
     "iopub.status.idle": "2022-08-08T06:45:16.610931Z",
     "shell.execute_reply": "2022-08-08T06:45:16.610254Z"
    },
    "papermill": {
     "duration": 38.559571,
     "end_time": "2022-08-08T06:45:16.625466",
     "exception": false,
     "start_time": "2022-08-08T06:44:38.065895",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (hidden): Linear(in_features=6, out_features=500, bias=True)\n",
      "  (hidden2): Linear(in_features=500, out_features=500, bias=True)\n",
      "  (predict): Linear(in_features=500, out_features=1, bias=True)\n",
      ")\n",
      "Epoch [200/600], Loss: 0.0101, Minimum Loss 0.010078, Val Loss 0.016552  \n",
      "Epoch [400/600], Loss: 0.0082, Minimum Loss 0.008163, Val Loss 0.016552  \n",
      "Epoch [600/600], Loss: 0.0078, Minimum Loss 0.007789, Val Loss 0.016552  \n"
     ]
    }
   ],
   "source": [
    "# torch can only train on Variable, so convert them to Variable\n",
    "x, y = Variable(x), Variable(y)\n",
    " \n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, n_feature, n_hidden, n_output):\n",
    "        super(Net, self).__init__()\n",
    "        self.hidden = torch.nn.Linear(n_feature, n_hidden)   # hidden layer\n",
    "        self.hidden2 = torch.nn.Linear(n_hidden, n_hidden)   # hidden layer\n",
    "        self.predict = torch.nn.Linear(n_hidden, n_output)   # output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.hidden(x))      # activation function for hidden layer\n",
    "        x = F.relu(self.hidden2(x))\n",
    "        x = self.predict(x)             # linear output\n",
    "        return x\n",
    "\n",
    "# use the same net as before      \n",
    "net = Net(n_feature=num_input, n_hidden=500, n_output=1)     # define the network\n",
    "print(net)  # net architecture\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.05)\n",
    "loss_func = torch.nn.MSELoss()  # this is for regression mean squared loss\n",
    "\n",
    "\n",
    "minimum_train_loss = 1e5\n",
    "minimum_val_loss = 1e5\n",
    "EPOCH = 600\n",
    "\n",
    "# start training\n",
    "for epoch in range(EPOCH):\n",
    "  \n",
    "    prediction = net(x)     # input x and predict based on x\n",
    "\n",
    "    loss = loss_func(prediction, y)     # must be (1. nn output, 2. target)\n",
    "\n",
    "    optimizer.zero_grad()   # clear gradients for next train\n",
    "    loss.backward()         # backpropagation, compute gradients\n",
    "    optimizer.step()        # apply gradients\n",
    "    \n",
    "    if loss<minimum_train_loss:\n",
    "        minimum_train_loss =loss\n",
    "        net_opt = net\n",
    "    \n",
    "    if epoch%200 == 199:\n",
    "      prediction = net_opt(i_val)\n",
    "      loss_val = loss_func(prediction, o_val)\n",
    "      if loss_val<minimum_val_loss:\n",
    "        minimum_val_loss = loss_val\n",
    "        net_opt_val = net_opt\n",
    "      print (\"Epoch [{}/{}], Loss: {:.4f}, Minimum Loss {:.6f}, Val Loss {:.6f}  \"  .format(epoch+1, EPOCH, loss, minimum_train_loss, minimum_val_loss))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 55.269162,
   "end_time": "2022-08-08T06:45:17.565246",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-08-08T06:44:22.296084",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
