{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "likely-filling",
   "metadata": {
    "papermill": {
     "duration": 0.012815,
     "end_time": "2022-08-07T23:16:18.904962",
     "exception": false,
     "start_time": "2022-08-07T23:16:18.892147",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "finished-smooth",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-07T23:16:18.931743Z",
     "iopub.status.busy": "2022-08-07T23:16:18.929961Z",
     "iopub.status.idle": "2022-08-07T23:16:19.060001Z",
     "shell.execute_reply": "2022-08-07T23:16:19.060793Z",
     "shell.execute_reply.started": "2022-08-07T08:49:18.254800Z"
    },
    "papermill": {
     "duration": 0.146495,
     "end_time": "2022-08-07T23:16:19.061236",
     "exception": false,
     "start_time": "2022-08-07T23:16:18.914741",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y(t-4)</th>\n",
       "      <th>y(t-3)</th>\n",
       "      <th>y(t-2)</th>\n",
       "      <th>y(t-1)</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Day</th>\n",
       "      <th>y(t)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1529.0</td>\n",
       "      <td>1561.0</td>\n",
       "      <td>1573.0</td>\n",
       "      <td>1559.0</td>\n",
       "      <td>16.835556</td>\n",
       "      <td>177.0</td>\n",
       "      <td>1565.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1561.0</td>\n",
       "      <td>1573.0</td>\n",
       "      <td>1559.0</td>\n",
       "      <td>1565.0</td>\n",
       "      <td>16.916944</td>\n",
       "      <td>177.0</td>\n",
       "      <td>1587.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1684.0</td>\n",
       "      <td>1695.0</td>\n",
       "      <td>1750.0</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>17.666944</td>\n",
       "      <td>177.0</td>\n",
       "      <td>1838.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1695.0</td>\n",
       "      <td>1750.0</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>1838.0</td>\n",
       "      <td>17.750556</td>\n",
       "      <td>177.0</td>\n",
       "      <td>1836.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1812.0</td>\n",
       "      <td>1805.0</td>\n",
       "      <td>1769.0</td>\n",
       "      <td>1758.0</td>\n",
       "      <td>18.500278</td>\n",
       "      <td>177.0</td>\n",
       "      <td>1773.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   y(t-4)  y(t-3)  y(t-2)  y(t-1)       Hour    Day    y(t)\n",
       "0  1529.0  1561.0  1573.0  1559.0  16.835556  177.0  1565.0\n",
       "1  1561.0  1573.0  1559.0  1565.0  16.916944  177.0  1587.0\n",
       "2  1684.0  1695.0  1750.0  1800.0  17.666944  177.0  1838.0\n",
       "3  1695.0  1750.0  1800.0  1838.0  17.750556  177.0  1836.0\n",
       "4  1812.0  1805.0  1769.0  1758.0  18.500278  177.0  1773.0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_csv_path = '../input/electricity-uk-grid-data-preparation/Wind_train.csv'\n",
    "test_csv_path = '../input/electricity-uk-grid-data-preparation/Wind_test.csv'\n",
    "val_csv_path = '../input/electricity-uk-grid-data-preparation/Wind_val.csv'\n",
    "\n",
    "import pandas as pd\n",
    "train_df = pd.read_csv(train_csv_path)\n",
    "val_df = pd.read_csv(val_csv_path)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "homeless-england",
   "metadata": {
    "papermill": {
     "duration": 0.00995,
     "end_time": "2022-08-07T23:16:19.085739",
     "exception": false,
     "start_time": "2022-08-07T23:16:19.075789",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Considerations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "coastal-florence",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-07T23:16:19.110006Z",
     "iopub.status.busy": "2022-08-07T23:16:19.109306Z",
     "iopub.status.idle": "2022-08-07T23:16:19.114033Z",
     "shell.execute_reply": "2022-08-07T23:16:19.114728Z",
     "shell.execute_reply.started": "2022-08-07T08:49:18.810957Z"
    },
    "papermill": {
     "duration": 0.018915,
     "end_time": "2022-08-07T23:16:19.114911",
     "exception": false,
     "start_time": "2022-08-07T23:16:19.095996",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Similar_event_count = 100\n",
    "sensitivity_consideration = 1\n",
    "error_sensitivity_consideration = 1\n",
    "\n",
    "# Error-Signal Ratio\n",
    "ES_ratio = \"Yes\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "historical-louisiana",
   "metadata": {
    "papermill": {
     "duration": 0.00994,
     "end_time": "2022-08-07T23:16:19.135255",
     "exception": false,
     "start_time": "2022-08-07T23:16:19.125315",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Arranging and Normalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "annoying-bread",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-07T23:16:19.159855Z",
     "iopub.status.busy": "2022-08-07T23:16:19.159132Z",
     "iopub.status.idle": "2022-08-07T23:16:30.421325Z",
     "shell.execute_reply": "2022-08-07T23:16:30.422495Z",
     "shell.execute_reply.started": "2022-08-07T08:49:18.818706Z"
    },
    "papermill": {
     "duration": 11.277134,
     "end_time": "2022-08-07T23:16:30.422824",
     "exception": false,
     "start_time": "2022-08-07T23:16:19.145690",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "tensor(3513.) tensor(0.) tensor([3472.0000, 3464.0000, 3473.0000, 3490.0000,   23.9208,  391.0000]) tensor([0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.7778e-04, 3.1000e+01])\n",
      "tensor([3472.0000, 3464.0000, 3473.0000, 3490.0000,   23.9206,  360.0000]) tensor(3513.)\n"
     ]
    }
   ],
   "source": [
    "input_=[]\n",
    "output_=[]\n",
    "for row in train_df.iloc:\n",
    "    input_.append((row[0:len(row)-1]).astype(float))\n",
    "    output_.append(row[-1])\n",
    "    \n",
    "i_val=[]\n",
    "o_val=[]\n",
    "for row in val_df.iloc:\n",
    "    i_val.append((row[0:len(row)-1]).astype(float))\n",
    "    o_val.append(row[-1])\n",
    "    \n",
    "num_input = len(row)-1;\n",
    "print(num_input)\n",
    "\n",
    "####################################################\n",
    "#\n",
    "# This code is written with the help of the demo:\n",
    "# https://medium.com/@benjamin.phillips22/simple-regression-with-neural-networks-in-pytorch-313f06910379\n",
    "#\n",
    "####################################################\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import imageio\n",
    "\n",
    "torch.manual_seed(1)    # reproducible\n",
    "\n",
    "x = torch.tensor(input_).float()  \n",
    "y = torch.tensor(output_).float()   \n",
    "new_shape = (len(y), 1)\n",
    "y = y.view(new_shape)\n",
    "\n",
    "\n",
    "i_val = torch.tensor(i_val).float()  \n",
    "o_val = torch.tensor(o_val).float()   \n",
    "new_shape = (len(o_val), 1)\n",
    "o_val = o_val.view(new_shape)\n",
    "\n",
    "\n",
    "\n",
    "max_y = torch.max(y[:,0])\n",
    "min_y =torch.min(y[:,0])\n",
    "\n",
    "max_x = torch.max(x,dim=0)\n",
    "min_x = torch.min(x,dim=0)\n",
    "\n",
    "print(max_y, min_y, max_x.values, min_x.values)\n",
    "\n",
    "range_y = max_y - min_y\n",
    "range_x = max_x.values - min_x.values\n",
    "\n",
    "print(range_x, range_y)\n",
    "\n",
    "    #Normalizing\n",
    "x = (x - min_x.values)/range_x\n",
    "y = (y - min_y)/range_y\n",
    "\n",
    "    #Normalizing\n",
    "i_val = (i_val - min_x.values)/range_x\n",
    "o_val = (o_val - min_y)/range_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "possible-following",
   "metadata": {
    "papermill": {
     "duration": 0.011003,
     "end_time": "2022-08-07T23:16:30.445528",
     "exception": false,
     "start_time": "2022-08-07T23:16:30.434525",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Prediction NN Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "remarkable-application",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-07T23:16:30.478890Z",
     "iopub.status.busy": "2022-08-07T23:16:30.478028Z",
     "iopub.status.idle": "2022-08-07T23:20:43.608333Z",
     "shell.execute_reply": "2022-08-07T23:20:43.608897Z"
    },
    "papermill": {
     "duration": 253.152774,
     "end_time": "2022-08-07T23:20:43.609093",
     "exception": false,
     "start_time": "2022-08-07T23:16:30.456319",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (hidden): Linear(in_features=6, out_features=500, bias=True)\n",
      "  (hidden2): Linear(in_features=500, out_features=500, bias=True)\n",
      "  (predict): Linear(in_features=500, out_features=1, bias=True)\n",
      ")\n",
      "Epoch [200/600], Loss: 0.0002, Minimum Loss 0.000212, Val Loss 0.000192  \n",
      "Epoch [400/600], Loss: 0.0001, Minimum Loss 0.000143, Val Loss 0.000130  \n",
      "Epoch [600/600], Loss: 0.0001, Minimum Loss 0.000138, Val Loss 0.000130  \n"
     ]
    }
   ],
   "source": [
    "# torch can only train on Variable, so convert them to Variable\n",
    "x, y = Variable(x), Variable(y)\n",
    " \n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, n_feature, n_hidden, n_output):\n",
    "        super(Net, self).__init__()\n",
    "        self.hidden = torch.nn.Linear(n_feature, n_hidden)   # hidden layer\n",
    "        self.hidden2 = torch.nn.Linear(n_hidden, n_hidden)   # hidden layer\n",
    "        self.predict = torch.nn.Linear(n_hidden, n_output)   # output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.hidden(x))      # activation function for hidden layer\n",
    "        x = F.relu(self.hidden2(x))\n",
    "        x = self.predict(x)             # linear output\n",
    "        return x\n",
    "\n",
    "# use the same net as before      \n",
    "net = Net(n_feature=num_input, n_hidden=500, n_output=1)     # define the network\n",
    "print(net)  # net architecture\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.05)\n",
    "loss_func = torch.nn.MSELoss()  # this is for regression mean squared loss\n",
    "\n",
    "\n",
    "minimum_train_loss = 1e5 #High initial values\n",
    "minimum_val_loss = 1e5\n",
    "EPOCH = 600\n",
    "\n",
    "# start training\n",
    "for epoch in range(EPOCH):\n",
    "  \n",
    "    prediction = net(x)     # input x and predict based on x\n",
    "\n",
    "    loss = loss_func(prediction, y)     # must be (1. nn output, 2. target)\n",
    "\n",
    "    optimizer.zero_grad()   # clear gradients for next train\n",
    "    loss.backward()         # backpropagation, compute gradients\n",
    "    optimizer.step()        # apply gradients\n",
    "    \n",
    "    if loss<minimum_train_loss:\n",
    "        minimum_train_loss =loss\n",
    "        net_opt = net\n",
    "    \n",
    "    if epoch%200 == 199:\n",
    "      prediction = net_opt(i_val)\n",
    "      loss_val = loss_func(prediction, o_val)\n",
    "      if loss_val<minimum_val_loss:\n",
    "        minimum_val_loss = loss_val\n",
    "        net_opt_val = net_opt\n",
    "      print (\"Epoch [{}/{}], Loss: {:.4f}, Minimum Loss {:.6f}, Val Loss {:.6f}  \"  .format(epoch+1, EPOCH, loss, minimum_train_loss, minimum_val_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protected-berry",
   "metadata": {
    "papermill": {
     "duration": 0.01167,
     "end_time": "2022-08-07T23:20:43.632833",
     "exception": false,
     "start_time": "2022-08-07T23:20:43.621163",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Computing Test Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "talented-techno",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-07T23:20:43.660996Z",
     "iopub.status.busy": "2022-08-07T23:20:43.659950Z",
     "iopub.status.idle": "2022-08-07T23:20:59.517642Z",
     "shell.execute_reply": "2022-08-07T23:20:59.518465Z"
    },
    "papermill": {
     "duration": 15.873993,
     "end_time": "2022-08-07T23:20:59.518747",
     "exception": false,
     "start_time": "2022-08-07T23:20:43.644754",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized Test Loss 0.00014338041\n",
      "Test Loss 1769.4818\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv(test_csv_path)\n",
    "\n",
    "i_test=[]\n",
    "o_test=[]\n",
    "for row in test_df.iloc:\n",
    "    i_test.append((row[0:len(row)-1]).astype(float))\n",
    "    o_test.append(row[-1])\n",
    "\n",
    "\n",
    "i_test, o_test = Variable(torch.tensor(i_test)).float(), Variable(torch.tensor(o_test).float())\n",
    "new_shape = (len(o_test), 1)\n",
    "o_test = o_test.view(new_shape)\n",
    "\n",
    "    #Normalizing\n",
    "i_test = (i_test - min_x.values)/range_x\n",
    "o_test = (o_test - min_y)/range_y\n",
    "\n",
    "prediction = net_opt_val(i_test)\n",
    "loss_test = loss_func(prediction, o_test)\n",
    "\n",
    "print(\"Normalized Test Loss\",loss_test.detach().numpy())\n",
    "\n",
    "loss_test = loss_test*range_y*range_y # As the loss function returns MSE\n",
    "\n",
    "print(\"Test Loss\",loss_test.detach().numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consolidated-gross",
   "metadata": {
    "papermill": {
     "duration": 0.01207,
     "end_time": "2022-08-07T23:20:59.544040",
     "exception": false,
     "start_time": "2022-08-07T23:20:59.531970",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# NN for Predicting Heteroscedastic Absolute Error of Previous NN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "mature-librarian",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-07T23:20:59.579893Z",
     "iopub.status.busy": "2022-08-07T23:20:59.579169Z",
     "iopub.status.idle": "2022-08-07T23:44:01.078875Z",
     "shell.execute_reply": "2022-08-07T23:44:01.079494Z"
    },
    "papermill": {
     "duration": 1381.523433,
     "end_time": "2022-08-07T23:44:01.079949",
     "exception": false,
     "start_time": "2022-08-07T23:20:59.556516",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (hidden): Linear(in_features=6, out_features=500, bias=True)\n",
      "  (hidden2): Linear(in_features=500, out_features=500, bias=True)\n",
      "  (predict): Linear(in_features=500, out_features=1, bias=True)\n",
      ")\n",
      "Error to Signal ratio: tensor(0.0012)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:446: UserWarning: Using a target size (torch.Size([20000])) that is different to the input size (torch.Size([20000, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [200/600], Loss: 0.0001, Minimum Loss 0.000079, Val Loss 0.187471  \n",
      "Epoch [400/600], Loss: 0.0001, Minimum Loss 0.000078, Val Loss 0.187464  \n",
      "Epoch [600/600], Loss: 0.0001, Minimum Loss 0.000078, Val Loss 0.187463  \n"
     ]
    }
   ],
   "source": [
    "y_e = torch.zeros(len(x), dtype=torch.float) # initializing a variable of that size\n",
    "\n",
    "for iter1 in range(len(x)):\n",
    "    current_input = x[iter1,:];\n",
    "    current_output = net_opt_val(current_input);\n",
    "    y_e[iter1] = torch.abs(current_output - y[iter1]) \n",
    "        \n",
    "x, y_e = Variable(x), Variable(y_e)\n",
    "net_e = Net(n_feature=num_input, n_hidden=500, n_output=1)     # define the network\n",
    "print(net_e)  # net architecture\n",
    "\n",
    "# Error to Signal ratio\n",
    "ratio_e_s = 0.5 #default\n",
    "if ES_ratio == \"Yes\":\n",
    "    ratio_e_s = torch.var(y_e)/torch.var(y)\n",
    "\n",
    "    \n",
    "print('Error to Signal ratio:', ratio_e_s)\n",
    "\n",
    "optimizer = torch.optim.Adam(net_e.parameters(), lr=0.05)\n",
    "\n",
    "minimum_train_loss = 1e5 #High initial values\n",
    "minimum_val_loss = 1e5\n",
    "EPOCH = 600\n",
    "\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "  \n",
    "    prediction = net_e(x)     # input x and predict based on x\n",
    "\n",
    "    loss = loss_func(prediction, y_e)     # must be (1. nn output, 2. target)\n",
    "\n",
    "    optimizer.zero_grad()   # clear gradients for next train\n",
    "    loss.backward()         # backpropagation, compute gradients\n",
    "    optimizer.step()        # apply gradients\n",
    "    \n",
    "    if loss<minimum_train_loss:\n",
    "        minimum_train_loss =loss\n",
    "        net_opt = net_e\n",
    "    \n",
    "    if epoch%200 == 199:\n",
    "        prediction = net_opt(i_val)\n",
    "        loss_val = loss_func(prediction, o_val)\n",
    "        if loss_val<minimum_val_loss:\n",
    "            minimum_val_loss = loss_val\n",
    "            net_opt_val_e = net_opt\n",
    "        print (\"Epoch [{}/{}], Loss: {:.4f}, Minimum Loss {:.6f}, Val Loss {:.6f}  \"  .format(epoch+1, EPOCH, loss, minimum_train_loss, minimum_val_loss))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "young-azerbaijan",
   "metadata": {
    "papermill": {
     "duration": 0.015526,
     "end_time": "2022-08-07T23:44:01.109563",
     "exception": false,
     "start_time": "2022-08-07T23:44:01.094037",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Minimim deviation based similarity finding for Uncertainty Bounds\n",
    "\n",
    "   Aim: To achieve all indexes of similar samples\n",
    "\n",
    "   Steps: \n",
    "\n",
    "1. Itertion over all Input combinations.\n",
    "\n",
    "2. Find all deviation by indexes \n",
    "   (sensitivity can be considered during the consideration of deviation)\n",
    "\n",
    "3. Save top 100 similar events\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dressed-farmer",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-07T23:44:01.144632Z",
     "iopub.status.busy": "2022-08-07T23:44:01.143551Z",
     "iopub.status.idle": "2022-08-08T05:23:24.558690Z",
     "shell.execute_reply": "2022-08-08T05:23:24.559859Z"
    },
    "papermill": {
     "duration": 20363.437632,
     "end_time": "2022-08-08T05:23:24.561456",
     "exception": false,
     "start_time": "2022-08-07T23:44:01.123824",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5 %  Complete\n",
      "5.5 %  Complete\n",
      "10.5 %  Complete\n",
      "15.5 %  Complete\n",
      "20.5 %  Complete\n",
      "25.5 %  Complete\n",
      "30.5 %  Complete\n",
      "35.5 %  Complete\n",
      "40.5 %  Complete\n",
      "45.5 %  Complete\n",
      "50.5 %  Complete\n",
      "55.50000000000001 %  Complete\n",
      "60.5 %  Complete\n",
      "65.5 %  Complete\n",
      "70.5 %  Complete\n",
      "75.5 %  Complete\n",
      "80.5 %  Complete\n",
      "85.5 %  Complete\n",
      "90.5 %  Complete\n",
      "95.5 %  Complete\n",
      "100% Complete in 323m 55s\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pickle as pkl\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "max_dev_index = np.zeros(shape=(len(x),2))\n",
    "Similarity = np.zeros(shape=(len(x),Similar_event_count+1))\n",
    "sensitivity = torch.ones(len(max_x.values), dtype=torch.float64) # just initializing a variable of that size\n",
    "error_sensitivity = torch.ones(len(max_x.values), dtype=torch.float64)\n",
    "iter_debug = 0\n",
    "since = time.time()\n",
    "\n",
    "for iter1 in range(len(x)):\n",
    "    current_input = x[iter1,:];\n",
    "    \n",
    "    # While considering only Sensitivity\n",
    "    if sensitivity_consideration == 1 and error_sensitivity_consideration ==0:\n",
    "        current_output = net_opt_val(current_input)\n",
    "        \n",
    "       # Determining Sensitivity near input[iter1]\n",
    "        for iter2 in range(len(current_input)): \n",
    "            current_input[iter2] = current_input[iter2] + range_x[iter2]/1e4\n",
    "            \n",
    "            sensitivity[iter2] = torch.abs(current_output - net_opt_val(current_input))\n",
    "            \n",
    "            current_input[iter2] = current_input[iter2] - range_x[iter2]/1e4\n",
    "        \n",
    "        sensitivity = sensitivity/torch.max(sensitivity)\n",
    "        #The highest sensitivity is considered one\n",
    "    \n",
    "    if sensitivity_consideration == 1 and error_sensitivity_consideration ==1:\n",
    "        current_output = net_opt_val(current_input)\n",
    "        current_error = net_opt_val_e(current_input)\n",
    "        # ratio, ratio_e_s= 0.5 while giving equal concentration to error and signal\n",
    "        \n",
    "       # Determining Sensitivity and Error Sensitivity near input[iter1]\n",
    "        for iter2 in range(len(current_input)): \n",
    "            current_input[iter2] = current_input[iter2] + range_x[iter2]/1e4\n",
    "            \n",
    "            sensitivity[iter2] = torch.abs(current_output - net_opt_val(current_input))\n",
    "            error_sensitivity[iter2] = torch.abs(current_error - net_opt_val_e(current_input))\n",
    "            \n",
    "            current_input[iter2] = current_input[iter2] - range_x[iter2]/1e4\n",
    "        \n",
    "        sensitivity = sensitivity/torch.max(sensitivity)*(1-ratio_e_s)\n",
    "        error_sensitivity = error_sensitivity/torch.max(error_sensitivity)* ratio_e_s\n",
    "        sensitivity = sensitivity + error_sensitivity\n",
    "        \n",
    "        #The highest sensitivity is considered half for each, then adding\n",
    "        \n",
    "    \n",
    "    for iter2 in range(len(x)):\n",
    "        max_dev_index[iter2][0] = torch.max(sensitivity*torch.abs(current_input-x[iter2,:])/range_x).detach().numpy()\n",
    "        max_dev_index[iter2][1] = iter2\n",
    "        \n",
    "    sort_dev_index = max_dev_index[np.argsort(max_dev_index[:, 0])]\n",
    "    Similarity_threshold = sort_dev_index[Similar_event_count][0]\n",
    "    matched_indexes = sort_dev_index[0:Similar_event_count,1]\n",
    "    \n",
    "    Similarity[iter1,0] = Similarity_threshold\n",
    "    Similarity[iter1,1:(Similar_event_count+1)] = matched_indexes\n",
    "    \n",
    "    if iter1%1000==100:   \n",
    "        print(iter1/len(x)*100, '%' '  Complete')\n",
    "        time_elapsed = time.time() - since\n",
    "        # Observing progres in Command Window\n",
    "        # May Take about hours to find all similar events for entire training data\n",
    "\n",
    "print('100% Complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))    \n",
    "\n",
    "fileName = './' + 'Similarity'\n",
    "fileObject = open(fileName, 'wb')\n",
    "\n",
    "pkl.dump(Similarity, fileObject)\n",
    "fileObject.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 22038.485864,
   "end_time": "2022-08-08T05:23:30.976815",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-08-07T23:16:12.490951",
   "version": "2.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
